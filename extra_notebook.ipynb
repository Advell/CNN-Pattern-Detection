{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\ntrain_dir = '/kaggle/input/herbarium-2022-fgvc9/train_images/'\ntest_dir = '/kaggle/input/herbarium-2022-fgvc9/test_images'\n\nwith open(\"/kaggle/input/herbarium-2022-fgvc9/train_metadata.json\") as json_file:\n    train_meta = json.load(json_file)\nwith open(\"/kaggle/input/herbarium-2022-fgvc9/test_metadata.json\") as json_file:\n    test_meta = json.load(json_file)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-26T16:05:55.469784Z","iopub.execute_input":"2023-04-26T16:05:55.470835Z","iopub.status.idle":"2023-04-26T16:06:05.171523Z","shell.execute_reply.started":"2023-04-26T16:05:55.470791Z","shell.execute_reply":"2023-04-26T16:06:05.170451Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"image_ids = [image[\"image_id\"] for image in train_meta[\"images\"]]\nimage_dirs = [train_dir + image['file_name'] for image in train_meta[\"images\"]]\ncategory_ids = [annotation['category_id'] for annotation in train_meta['annotations']]\ngenus_ids = [annotation['genus_id'] for annotation in train_meta['annotations']]\n\ntest_ids = [image['image_id'] for image in test_meta]\ntest_dirs = [test_dir + image['file_name'] for image in test_meta]\n\n#Create the initial training dataframe with the above defined columns\ntrain_df = pd.DataFrame({\n    \"image_id\" : image_ids,\n    \"image_dir\" : image_dirs,\n    \"category\" : category_ids,\n    \"genus\" : genus_ids})\n\n#Create a testing dataframe\ntest_df = pd.DataFrame({\n    \"test_id\" : test_ids,\n    \"test_dir\" : test_dirs\n})\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:06:05.173504Z","iopub.execute_input":"2023-04-26T16:06:05.175189Z","iopub.status.idle":"2023-04-26T16:06:06.209139Z","shell.execute_reply.started":"2023-04-26T16:06:05.175145Z","shell.execute_reply":"2023-04-26T16:06:06.207932Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"          image_id                                          image_dir  \\\n0       00000__001  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n1       00000__002  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n2       00000__003  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n3       00000__004  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n4       00000__005  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n...            ...                                                ...   \n839767  15504__032  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839768  15504__033  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839769  15504__035  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839770  15504__036  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839771  15504__037  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n\n        category  genus  \n0              0      1  \n1              0      1  \n2              0      1  \n3              0      1  \n4              0      1  \n...          ...    ...  \n839767     15504   2584  \n839768     15504   2584  \n839769     15504   2584  \n839770     15504   2584  \n839771     15504   2584  \n\n[839772 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>image_dir</th>\n      <th>category</th>\n      <th>genus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000__001</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000__002</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000__003</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000__004</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000__005</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>839767</th>\n      <td>15504__032</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>2584</td>\n    </tr>\n    <tr>\n      <th>839768</th>\n      <td>15504__033</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>2584</td>\n    </tr>\n    <tr>\n      <th>839769</th>\n      <td>15504__035</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>2584</td>\n    </tr>\n    <tr>\n      <th>839770</th>\n      <td>15504__036</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>2584</td>\n    </tr>\n    <tr>\n      <th>839771</th>\n      <td>15504__037</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>2584</td>\n    </tr>\n  </tbody>\n</table>\n<p>839772 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Add a genus column to the dataframe\ngenus_map = {genus['genus_id'] : genus['genus'] for genus in train_meta['genera']}\ntrain_df['genus'] = train_df['genus'].map(genus_map)\n\n##Create a family column in the dataframe based on the genus names\n    # Step 1: Create dictionary of genus -> family mapping\ngenus_family_map = {}\nfor category in train_meta[\"categories\"]:\n    genus = category['genus']\n    family = category['family']\n    genus_family_map[genus] = family\n\n    # Step 2: Create new column with default value of None™\ntrain_df['family'] = None\n\n    # Step 3: Update values in new column based on genus -> family mapping\nfor i, row in train_df.iterrows():\n    genus = row['genus']\n    if genus in genus_family_map:\n        family = genus_family_map[genus]\n        train_df.at[i, 'family'] = family\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:06:06.210797Z","iopub.execute_input":"2023-04-26T16:06:06.211467Z","iopub.status.idle":"2023-04-26T16:06:53.563021Z","shell.execute_reply.started":"2023-04-26T16:06:06.211425Z","shell.execute_reply":"2023-04-26T16:06:53.560918Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"          image_id                                          image_dir  \\\n0       00000__001  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n1       00000__002  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n2       00000__003  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n3       00000__004  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n4       00000__005  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n...            ...                                                ...   \n839767  15504__032  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839768  15504__033  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839769  15504__035  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839770  15504__036  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n839771  15504__037  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n\n        category        genus          family  \n0              0        Abies        Pinaceae  \n1              0        Abies        Pinaceae  \n2              0        Abies        Pinaceae  \n3              0        Abies        Pinaceae  \n4              0        Abies        Pinaceae  \n...          ...          ...             ...  \n839767     15504  Zygophyllum  Zygophyllaceae  \n839768     15504  Zygophyllum  Zygophyllaceae  \n839769     15504  Zygophyllum  Zygophyllaceae  \n839770     15504  Zygophyllum  Zygophyllaceae  \n839771     15504  Zygophyllum  Zygophyllaceae  \n\n[839772 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>image_dir</th>\n      <th>category</th>\n      <th>genus</th>\n      <th>family</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000__001</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>Abies</td>\n      <td>Pinaceae</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000__002</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>Abies</td>\n      <td>Pinaceae</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000__003</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>Abies</td>\n      <td>Pinaceae</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000__004</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>Abies</td>\n      <td>Pinaceae</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000__005</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>0</td>\n      <td>Abies</td>\n      <td>Pinaceae</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>839767</th>\n      <td>15504__032</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>Zygophyllum</td>\n      <td>Zygophyllaceae</td>\n    </tr>\n    <tr>\n      <th>839768</th>\n      <td>15504__033</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>Zygophyllum</td>\n      <td>Zygophyllaceae</td>\n    </tr>\n    <tr>\n      <th>839769</th>\n      <td>15504__035</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>Zygophyllum</td>\n      <td>Zygophyllaceae</td>\n    </tr>\n    <tr>\n      <th>839770</th>\n      <td>15504__036</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>Zygophyllum</td>\n      <td>Zygophyllaceae</td>\n    </tr>\n    <tr>\n      <th>839771</th>\n      <td>15504__037</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15504</td>\n      <td>Zygophyllum</td>\n      <td>Zygophyllaceae</td>\n    </tr>\n  </tbody>\n</table>\n<p>839772 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Filter only the images of plants that are in the Poaceae family\ntrain_df = train_df.loc[train_df['family'] == 'Poaceae']\n#Reset index\ntrain_df = train_df.reset_index(drop=True)\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:06:53.565938Z","iopub.execute_input":"2023-04-26T16:06:53.566558Z","iopub.status.idle":"2023-04-26T16:06:53.639897Z","shell.execute_reply.started":"2023-04-26T16:06:53.566517Z","shell.execute_reply":"2023-04-26T16:06:53.638960Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"         image_id                                          image_dir  \\\n0      00333__001  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n1      00333__002  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n2      00333__003  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n3      00333__004  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n4      00333__005  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n...           ...                                                ...   \n53542  15501__101  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n53543  15501__103  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n53544  15501__105  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n53545  15501__106  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n53546  15501__107  /kaggle/input/herbarium-2022-fgvc9/train_image...   \n\n       category      genus   family  \n0           333   Agrostis  Poaceae  \n1           333   Agrostis  Poaceae  \n2           333   Agrostis  Poaceae  \n3           333   Agrostis  Poaceae  \n4           333   Agrostis  Poaceae  \n...         ...        ...      ...  \n53542     15501  Zuloagaea  Poaceae  \n53543     15501  Zuloagaea  Poaceae  \n53544     15501  Zuloagaea  Poaceae  \n53545     15501  Zuloagaea  Poaceae  \n53546     15501  Zuloagaea  Poaceae  \n\n[53547 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>image_dir</th>\n      <th>category</th>\n      <th>genus</th>\n      <th>family</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00333__001</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>333</td>\n      <td>Agrostis</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00333__002</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>333</td>\n      <td>Agrostis</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00333__003</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>333</td>\n      <td>Agrostis</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00333__004</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>333</td>\n      <td>Agrostis</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00333__005</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>333</td>\n      <td>Agrostis</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53542</th>\n      <td>15501__101</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15501</td>\n      <td>Zuloagaea</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>53543</th>\n      <td>15501__103</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15501</td>\n      <td>Zuloagaea</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>53544</th>\n      <td>15501__105</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15501</td>\n      <td>Zuloagaea</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>53545</th>\n      <td>15501__106</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15501</td>\n      <td>Zuloagaea</td>\n      <td>Poaceae</td>\n    </tr>\n    <tr>\n      <th>53546</th>\n      <td>15501__107</td>\n      <td>/kaggle/input/herbarium-2022-fgvc9/train_image...</td>\n      <td>15501</td>\n      <td>Zuloagaea</td>\n      <td>Poaceae</td>\n    </tr>\n  </tbody>\n</table>\n<p>53547 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df[\"genus\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:06:53.641333Z","iopub.execute_input":"2023-04-26T16:06:53.641799Z","iopub.status.idle":"2023-04-26T16:06:53.652953Z","shell.execute_reply.started":"2023-04-26T16:06:53.641761Z","shell.execute_reply":"2023-04-26T16:06:53.651772Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"Muhlenbergia       4228\nPaspalum           3124\nPoa                2608\nDichanthelium      2474\nSporobolus         2304\n                   ... \nPtilagrostiella      14\nRhipidocladum        11\nDupontia             10\nKalinia              10\nBarkworthia           8\nName: genus, Length: 158, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model creating","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\n\n!pip install fvcore","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:07.059147Z","iopub.execute_input":"2023-04-26T16:09:07.060128Z","iopub.status.idle":"2023-04-26T16:09:17.413065Z","shell.execute_reply.started":"2023-04-26T16:09:07.060078Z","shell.execute_reply":"2023-04-26T16:09:17.411779Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Requirement already satisfied: fvcore in /opt/conda/lib/python3.7/site-packages (0.1.5.post20221221)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore) (1.21.6)\nRequirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from fvcore) (0.1.8)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from fvcore) (9.4.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from fvcore) (0.9.0)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from fvcore) (2.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fvcore) (4.64.1)\nRequirement already satisfied: iopath>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from fvcore) (0.1.10)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore) (6.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from iopath>=0.1.7->fvcore) (4.4.0)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath>=0.1.7->fvcore) (2.7.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"df = train_df\n# Split the dataset for each class separately\ntrain_dfs = []\nval_dfs = []\nfor label in df['genus'].unique():\n    # Filter the dataset to only include images with the current label\n    label_df = df[df['genus'] == label]\n    \n    # Split the dataset into training and evaluation sets\n    train_df, val_df = train_test_split(label_df, test_size=0.2)\n    \n    # Append the training and evaluation sets to their respective lists\n    train_dfs.append(train_df)\n    val_dfs.append(val_df)\n\n# Concatenate the training and evaluation sets for all classes into single DataFrames\ntrain_df = pd.concat(train_dfs)\nval_df = pd.concat(val_dfs)\n\ntrain_df['genus'] = pd.factorize(train_df['genus'])[0]\nval_df['genus'] = pd.factorize(val_df['genus'])[0]","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:17.415962Z","iopub.execute_input":"2023-04-26T16:09:17.416383Z","iopub.status.idle":"2023-04-26T16:09:18.324155Z","shell.execute_reply.started":"2023-04-26T16:09:17.416337Z","shell.execute_reply":"2023-04-26T16:09:18.323065Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nepochs = 4\nIM_SIZE = 224\nlearning_rate = 1e-3\n\nX_train, Y_train = train_df[\"image_dir\"].values, train_df[\"genus\"].values\n\nX_val, Y_val = val_df[\"image_dir\"].values, val_df[\"genus\"].values\n\nTransform = transforms.Compose([\n     transforms.Resize((IM_SIZE, IM_SIZE)),\n     transforms.ToTensor(),\n     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:18.325626Z","iopub.execute_input":"2023-04-26T16:09:18.326677Z","iopub.status.idle":"2023-04-26T16:09:18.334879Z","shell.execute_reply.started":"2023-04-26T16:09:18.326632Z","shell.execute_reply":"2023-04-26T16:09:18.333458Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"class GetData(Dataset):\n    def __init__(self, FNames, Labels, Transform):\n        self.fnames = FNames\n        self.transform = Transform\n        self.labels = Labels         \n        \n    def __len__(self):\n        return len(self.fnames)\n\n    def __getitem__(self, index):       \n        x = Image.open(self.fnames[index])\n    \n        if \"train\" in self.fnames[index]:             \n            return self.transform(x), self.labels[index]\n        elif \"test\" in self.fnames[index]:            \n            return self.transform(x), self.fnames[index]\n\n                \ntrainset = GetData(X_train, Y_train, Transform)\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\nvalset = GetData(X_val, Y_val, Transform)\nvalloader = DataLoader(valset, batch_size=batch_size, shuffle=True)\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nmodel = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True)            ","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:18.338179Z","iopub.execute_input":"2023-04-26T16:09:18.338538Z","iopub.status.idle":"2023-04-26T16:09:19.669816Z","shell.execute_reply.started":"2023-04-26T16:09:18.338500Z","shell.execute_reply":"2023-04-26T16:09:19.662662Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/zhanghang1989_ResNeSt_master\n","output_type":"stream"}]},{"cell_type":"code","source":"num_classes = train_df['genus'].nunique()\nclass_counts = np.bincount(Y_train)\n\nprint(num_classes)\nprint(class_counts)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:19.673702Z","iopub.execute_input":"2023-04-26T16:09:19.674063Z","iopub.status.idle":"2023-04-26T16:09:19.693683Z","shell.execute_reply.started":"2023-04-26T16:09:19.674029Z","shell.execute_reply":"2023-04-26T16:09:19.692291Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"158\n[ 706   11  240   12  121  739  117   60  118   16 1560   48  112   57\n  216    6   44   83  405 1141  124 1166  629   60  461   24   56  200\n  407   14  116   22  252   56   59  104  422  192   90 1979  696   52\n   53  115    8  448   32  135  978   57 1654  397   60  995  120  240\n 1175  684  124  209   57   61   53   33  199  266   53  219   62  141\n   71   40   52    8   58  116  283  288  471  371   56   60  117  752\n   36   56   48 3382  124  367   14   57  172   74   43   62   26 1132\n  164   60 2499   59  262  149   44   54   61  219  103 2086   76  132\n   60   56   11   11    8  168  228   60   54  298   57   56   39 1029\n   16   32  232   56  328 1843  130  149   57   29   11   21   57   55\n   24  329   52   55  120   36  111   45   15   70  534   37   30   16\n   46   80   48   48]\n","output_type":"stream"}]},{"cell_type":"code","source":"total_layers = len(list(model.parameters()))\n\nfor param in model.parameters():\n    param.requires_grad = True\n    \nn_inputs = model.fc.in_features\nlast_layer = nn.Linear(n_inputs, num_classes)\nmodel.fc = last_layer \nif torch.cuda.is_available():\n    model.cuda()\nprint(model.fc.out_features)    \n\nif torch.cuda.is_available():\n    class_weights = class_weights.cuda()\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:19.695538Z","iopub.execute_input":"2023-04-26T16:09:19.695902Z","iopub.status.idle":"2023-04-26T16:09:19.798999Z","shell.execute_reply.started":"2023-04-26T16:09:19.695864Z","shell.execute_reply":"2023-04-26T16:09:19.797895Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"158\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"X = train_df['image_dir'].values\nY = train_df['genus'].values\n\n# Split the dataset into training and validation sets\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n\n# Create the training and validation datasets\ntrain_dataset = CustomDataset(X_train, Y_train, transform=data_transforms, transform_no_aug=transform_no_aug, min_samples=20)\nval_dataset = CustomDataset(X_val, Y_val, transform=transform_no_aug)  # Apply only the non-augmented transform to validation set\n\n# Create the DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\nprint(\"Size of the training dataset:\", len(X_val))\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:19.800442Z","iopub.execute_input":"2023-04-26T16:09:19.800880Z","iopub.status.idle":"2023-04-26T16:09:19.811031Z","shell.execute_reply.started":"2023-04-26T16:09:19.800842Z","shell.execute_reply":"2023-04-26T16:09:19.807403Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"'X = train_df[\\'image_dir\\'].values\\nY = train_df[\\'genus\\'].values\\n\\n# Split the dataset into training and validation sets\\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\\n\\n# Create the training and validation datasets\\ntrain_dataset = CustomDataset(X_train, Y_train, transform=data_transforms, transform_no_aug=transform_no_aug, min_samples=20)\\nval_dataset = CustomDataset(X_val, Y_val, transform=transform_no_aug)  # Apply only the non-augmented transform to validation set\\n\\n# Create the DataLoaders\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\\n\\nprint(\"Size of the training dataset:\", len(X_val))'"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import f1_score\n\ndef train(trainloader, model, criterion, optimizer, scaler, device=torch.device(\"cpu\")):\n    train_acc = 0.0\n    train_loss = 0.0\n    y_true = []\n    y_pred = []\n    for images, labels in tqdm(trainloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast(enabled=True):\n            output = model(images)\n            loss = criterion(output, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            acc = ((output.argmax(dim=1) == labels).float().mean())\n            train_acc += acc\n            train_loss += loss\n            y_true += labels.cpu().numpy().tolist()\n            y_pred += output.argmax(dim=1).cpu().numpy().tolist()\n            \n    train_f1 = f1_score(y_true, y_pred, average=None)\n    train_f1_avg = f1_score(y_true, y_pred, average='macro')\n    return train_acc/len(trainloader), train_loss/len(trainloader), train_f1, train_f1_avg","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:19.812573Z","iopub.execute_input":"2023-04-26T16:09:19.813606Z","iopub.status.idle":"2023-04-26T16:09:19.823798Z","shell.execute_reply.started":"2023-04-26T16:09:19.813569Z","shell.execute_reply":"2023-04-26T16:09:19.822750Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"def evaluate(testloader, model, criterion, device=torch.device(\"cpu\")):\n    eval_acc = 0.0\n    eval_loss = 0.0\n    y_true = []\n    y_pred = []\n    for images, labels in tqdm(testloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        with torch.no_grad():\n            output = model(images)\n            loss = criterion(output, labels)\n        acc = ((output.argmax(dim=1) == labels).float().mean())\n        eval_acc += acc\n        eval_loss += loss\n        y_true += labels.cpu().numpy().tolist()\n        y_pred += output.argmax(dim=1).cpu().numpy().tolist()\n  \n    eval_f1 = f1_score(y_true, y_pred, average=None)\n    eval_f1_avg = f1_score(y_true, y_pred, average='macro')\n    return eval_acc/len(testloader), eval_loss/len(testloader), eval_f1, eval_f1_avg","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:19.825216Z","iopub.execute_input":"2023-04-26T16:09:19.825660Z","iopub.status.idle":"2023-04-26T16:09:19.836097Z","shell.execute_reply.started":"2023-04-26T16:09:19.825618Z","shell.execute_reply":"2023-04-26T16:09:19.835138Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler(enabled=True)\n\ntrain_f1_scores = []  # Initialize an empty list to store training F1 scores\nval_f1_scores = []  # Initialize an empty list to store validation F1 scores\ntrain_losses = []\nval_losses = []\n\n\nfor epoch in range(epochs):\n    train_acc, train_loss, train_f1, train_f1_avg = train(trainloader, model, criterion, optimizer, scaler, device=device)\n    eval_acc, eval_loss, eval_f1, eval_f1_avg = evaluate(valloader, model, criterion, device=torch.device(\"cuda\"))\n\n    train_f1_scores.append(train_f1_avg)  # Store the training F1 score for this epoch\n    val_f1_scores.append(eval_f1_avg)  # Store the validation F1 score for this epoch\n    train_losses.append(train_loss)\n    val_losses.append(eval_loss)\n\n    print(f\"Epoch {epoch + 1} | Train Acc: {train_acc*100} | Train Loss: {train_loss} | Train F1 (Avg): {train_f1_avg}\")\n    print(f\"\\t Val Acc: {eval_acc*100} | Val Loss: {eval_loss} | Val F1 (Avg): {eval_f1_avg}\")\n    \n    print(\"F1 score per class (Train):\")\n    for i, f1 in enumerate(train_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"\\nF1 score per class (Validation):\") \n    for i, f1 in enumerate(eval_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"====\"*8)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:09:19.839664Z","iopub.execute_input":"2023-04-26T16:09:19.840233Z","iopub.status.idle":"2023-04-26T16:09:24.056832Z","shell.execute_reply.started":"2023-04-26T16:09:19.840205Z","shell.execute_reply":"2023-04-26T16:09:24.054980Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"  0%|          | 0/335 [00:04<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3489502070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0meval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_f1_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/3871187774.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainloader, model, criterion, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/zhanghang1989_ResNeSt_master/resnest/torch/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/zhanghang1989_ResNeSt_master/resnest/torch/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/zhanghang1989_ResNeSt_master/resnest/torch/models/splat.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mattens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrchannel\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplited\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matten\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 15.90 GiB total capacity; 14.85 GiB already allocated; 53.75 MiB free; 14.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 15.90 GiB total capacity; 14.85 GiB already allocated; 53.75 MiB free; 14.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"# Assuming `train_f1_scores` and `val_f1_scores` are the lists with the F1 scores for each epoch\nepochs_range = range(1, 3 + 1)\n\nplt.figure(figsize=(10, 5))\nplt.plot(epochs_range, train_f1_scores, label='Training F1')\nplt.plot(epochs_range, val_f1_scores, label='Validation F1')\nplt.xlabel('Epochs')\nplt.ylabel('F1 Score')\nplt.title('F1 Score vs. Epochs')\nplt.legend()\nplt.show()\n\nplt.plot(epochs_range, train_losses, label=\"Training Loss\")\nplt.plot(epochs_range, val_losses, label=\"Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss Over Epochs\")\nplt.legend()\nplt.show()\n\n#plt.plot(np.arange(len(training_losses))-0.5, training_losses)\n#plt.plot(validation_losses)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:07:13.699383Z","iopub.status.idle":"2023-04-26T16:07:13.700248Z","shell.execute_reply.started":"2023-04-26T16:07:13.699988Z","shell.execute_reply":"2023-04-26T16:07:13.700015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install grad-cam\nfrom grad_cam import GradCAM\n\n# Create a GradCAM object for your model\ngradcam = GradCAM(model=model, feature_module=model.layer4, target_layer_names=[\"2\"], use_cuda=True)\n\n# Choose an image from the validation set\nimage, label = valset[0]\nimage = image.unsqueeze(0).to(device)  # Add a batch dimension\n\n# Get the class activation map\ncam = gradcam(image)\n\n# Visualize the results\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef show_cam_on_image(img, mask):\n    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n    heatmap = np.float32(heatmap) / 255\n    cam = heatmap + np.float32(img)\n    cam = cam / np.max(cam)\n    return np.uint8(255 * cam)\n\nimage = image.squeeze(0).cpu().numpy().transpose(1, 2, 0)  # Convert the image back to the original shape\nimage = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Denormalize the image\nimage = np.clip(image, 0, 1)\n\ncam_image = show_cam_on_image(image, cam)\n\nplt.imshow(cam_image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:07:13.701737Z","iopub.status.idle":"2023-04-26T16:07:13.702637Z","shell.execute_reply.started":"2023-04-26T16:07:13.702347Z","shell.execute_reply":"2023-04-26T16:07:13.702390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"scaler2 = torch.cuda.amp.GradScaler(enabled=True)\nepochs2 = 10\nfor epoch in range(epochs2):\n    train_acc, train_loss, train_f1, train_f1_avg = train(trainloader, model, criterion, optimizer, scaler, device=device)\n    eval_acc, eval_loss, eval_f1, eval_f1_avg = evaluate(valloader, model, criterion, device=torch.device(\"cuda\"))\n\n    print(f\"Epoch {epoch + 1} | Train Acc: {train_acc*100} | Train Loss: {train_loss} | Train F1 (Avg): {train_f1_avg}\")\n    print(f\"\\t Val Acc: {eval_acc*100} | Val Loss: {eval_loss} | Val F1 (Avg): {eval_f1_avg}\")\n    \n    print(\"F1 score per class (Train):\")\n    for i, f1 in enumerate(train_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"\\nF1 score per class (Validation):\") \n    for i, f1 in enumerate(eval_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"====\"*8)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-04-26T16:07:13.704256Z","iopub.status.idle":"2023-04-26T16:07:13.705125Z","shell.execute_reply.started":"2023-04-26T16:07:13.704839Z","shell.execute_reply":"2023-04-26T16:07:13.704866Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}