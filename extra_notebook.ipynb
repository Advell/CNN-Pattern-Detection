{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\ntrain_dir = '/kaggle/input/herbarium-2022-fgvc9/train_images/'\ntest_dir = '/kaggle/input/herbarium-2022-fgvc9/test_images'\n\nwith open(\"/kaggle/input/herbarium-2022-fgvc9/train_metadata.json\") as json_file:\n    train_meta = json.load(json_file)\nwith open(\"/kaggle/input/herbarium-2022-fgvc9/test_metadata.json\") as json_file:\n    test_meta = json.load(json_file)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-24T10:49:46.836368Z","iopub.execute_input":"2023-03-24T10:49:46.836646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = [image[\"image_id\"] for image in train_meta[\"images\"]]\nimage_dirs = [train_dir + image['file_name'] for image in train_meta[\"images\"]]\ncategory_ids = [annotation['category_id'] for annotation in train_meta['annotations']]\ngenus_ids = [annotation['genus_id'] for annotation in train_meta['annotations']]\n\ntest_ids = [image['image_id'] for image in test_meta]\ntest_dirs = [test_dir + image['file_name'] for image in test_meta]\n\n#Create the initial training dataframe with the above defined columns\ntrain_df = pd.DataFrame({\n    \"image_id\" : image_ids,\n    \"image_dir\" : image_dirs,\n    \"category\" : category_ids,\n    \"genus\" : genus_ids})\n\n#Create a testing dataframe\ntest_df = pd.DataFrame({\n    \"test_id\" : test_ids,\n    \"test_dir\" : test_dirs\n})\n\ntrain_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add a genus column to the dataframe\ngenus_map = {genus['genus_id'] : genus['genus'] for genus in train_meta['genera']}\ntrain_df['genus'] = train_df['genus'].map(genus_map)\n\n##Create a family column in the datagframe based on the genus names\n    # Step 1: Create dictionary of genus -> family mapping\ngenus_family_map = {}\nfor category in train_meta[\"categories\"]:\n    genus = category['genus']\n    family = category['family']\n    genus_family_map[genus] = family\n\n    # Step 2: Create new column with default value of Noneâ„¢\ntrain_df['family'] = None\n\n    # Step 3: Update values in new column based on genus -> family mapping\nfor i, row in train_df.iterrows():\n    genus = row['genus']\n    if genus in genus_family_map:\n        family = genus_family_map[genus]\n        train_df.at[i, 'family'] = family\n\ntrain_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filter only the images of plants that are in the Poaceae family\ntrain_df = train_df.loc[train_df['family'] == 'Poaceae']\n#Reset index\ntrain_df = train_df.reset_index(drop=True)\n\ntrain_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"genus\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport random\n\n!pip install git+https://github.com/facebookresearch/fvcore.git\n\ndf = train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nepochs = 10\nIM_SIZE = 256\nlearning_rate = 1e-4\n\n#Define the data augmentation transformations\ndata_transforms = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Define the transformations without data augmentation\ntransform_no_aug = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, X, Y, transform=None, transform_no_aug=None, min_samples=20):\n        self.X = X\n        self.Y = Y\n        self.transform = transform\n        self.transform_no_aug = transform_no_aug\n        self.min_samples = min_samples\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        img_path = self.X[idx]\n        label = self.Y[idx]\n        \n        img = Image.open(img_path)\n        \n        if self.transform and self.transform_no_aug:\n            label_count = len([y for y in self.Y if y == label])\n            if label_count < self.min_samples:\n                img = self.transform(img)\n            else:\n                img = self.transform_no_aug(img)\n        \n        return img, label\n\nnum_classes = train_df['genus'].nunique()\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nmodel = torch.hub.load('zhanghang1989/ResNeSt', 'resnest101', pretrained=True, )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_df['image_dir'].values\nY = train_df['genus'].values\n\n# Split the dataset into training and validation sets\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n\n# Create the training and validation datasets\ntrain_dataset = CustomDataset(X_train, Y_train, transform=data_transforms, transform_no_aug=transform_no_aug, min_samples=20)\nval_dataset = CustomDataset(X_val, Y_val, transform=transform_no_aug)  # Apply only the non-augmented transform to validation set\n\n# Create the DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\nprint(\"Size of the training dataset:\", len(X_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.fc.in_features) \nprint(model.fc.out_features)\n    \nn_inputs = model.fc.in_features\nlast_layer = nn.Linear(n_inputs, num_classes)\nmodel.fc = last_layer\n\nfor idx, (name, param) in enumerate(model.named_parameters()):\n    if idx < len(list(model.named_parameters())) - 1:\n        param.requires_grad = False\n\nprint(model.fc.out_features)    \n\nif torch.cuda.is_available():\n    model.cuda()\n    \ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.fc.parameters(), learning_rate) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import f1_score\n\ndef train(trainloader, model, criterion, optimizer, scaler, device=torch.device(\"cpu\")):\n    train_acc = 0.0\n    train_loss = 0.0\n    y_true = []\n    y_pred = []\n    for images, labels in tqdm(trainloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast(enabled=True):\n            output = model(images)\n            loss = criterion(output, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            acc = ((output.argmax(dim=1) == labels).float().mean())\n            train_acc += acc\n            train_loss += loss\n            y_true += labels.cpu().numpy().tolist()\n            y_pred += output.argmax(dim=1).cpu().numpy().tolist()\n            \n    train_f1 = f1_score(y_true, y_pred, average=None)\n    return train_acc/len(trainloader), train_loss/len(trainloader), train_f1               ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(testloader, model, criterion, device=torch.device(\"cpu\")):\n    eval_acc = 0.0\n    eval_loss = 0.0\n    y_true = []\n    y_pred = []\n    for images, labels in tqdm(testloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        with torch.no_grad():\n            output = model(images)\n            loss = criterion(output, labels)\n        acc = ((output.argmax(dim=1) == labels).float().mean())\n        eval_acc += acc\n        eval_loss += loss\n        y_true += labels.cpu().numpy().tolist()\n        y_pred += output.argmax(dim=1).cpu().numpy().tolist()\n  \n    eval_f1 = f1_score(y_true, y_pred, average=None)\n    return eval_acc/len(testloader), eval_loss/len(testloader), eval_f1    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler(enabled=True)\nfor epoch in range(epochs):\n    train_acc, train_loss, train_f1 = train(trainloader, model, criterion, optimizer, scaler, device=device)\n    eval_acc, eval_loss, eval_f1 = evaluate(valloader, model, criterion, device=torch.device(\"cuda\"))\n\n    print(f\"Epoch {epoch + 1} | Train Acc: {train_acc*100} | Train Loss: {train_loss} | Train F1: {train_f1}\")\n    print(f\"\\t Val Acc: {eval_acc*100} | Val Loss: {eval_loss} | Val F1: {eval_f1}\")\n    \n    print(\"F1 score per class (Train):\")\n    for i, f1 in enumerate(train_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"\\nF1 score per class (Validation):\")\n    for i, f1 in enumerate(eval_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"====\"*8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}