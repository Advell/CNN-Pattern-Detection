{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\ntrain_dir = '../input/herbarium-2022-fgvc9/train_images/'\ntest_dir = '../input/herbarium-2022-fgvc9/test_images/'\n\nwith open(\"../input/herbarium-2022-fgvc9/train_metadata.json\") as json_file:\n    train_meta = json.load(json_file)\nwith open(\"../input/herbarium-2022-fgvc9/test_metadata.json\") as json_file:\n    test_meta = json.load(json_file)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-28T18:42:36.568032Z","iopub.execute_input":"2023-04-28T18:42:36.568319Z","iopub.status.idle":"2023-04-28T18:42:50.293682Z","shell.execute_reply.started":"2023-04-28T18:42:36.568292Z","shell.execute_reply":"2023-04-28T18:42:50.292501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_ids = [image[\"image_id\"] for image in train_meta[\"images\"]]\nimage_dirs = [train_dir + image['file_name'] for image in train_meta[\"images\"]]\ncategory_ids = [annotation['category_id'] for annotation in train_meta['annotations']]\ngenus_ids = [annotation['genus_id'] for annotation in train_meta['annotations']]\n\ntest_ids = [image['image_id'] for image in test_meta]\ntest_dirs = [test_dir + image['file_name'] for image in test_meta]\n\n#Create the initial training dataframe with the above defined columns\nmain_df = pd.DataFrame({\n    \"image_id\" : image_ids,\n    \"image_dir\" : image_dirs,\n    \"category\" : category_ids,\n    \"genus\" : genus_ids})\n\n#Create a testing dataframe\nNever_used = pd.DataFrame({\n    \"test_id\" : test_ids,\n    \"test_dir\" : test_dirs\n})\n\nmain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:42:50.295855Z","iopub.execute_input":"2023-04-28T18:42:50.296286Z","iopub.status.idle":"2023-04-28T18:42:51.378316Z","shell.execute_reply.started":"2023-04-28T18:42:50.296252Z","shell.execute_reply":"2023-04-28T18:42:51.377012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Add a genus column to the dataframe\ngenus_map = {genus['genus_id'] : genus['genus'] for genus in train_meta['genera']}\nmain_df['genus'] = main_df['genus'].map(genus_map)\n\n##Create a family column in the datagframe based on the genus names\n    # Step 1: Create dictionary of genus -> family mapping\ngenus_family_map = {}\nfor category in train_meta[\"categories\"]:\n    genus = category['genus']\n    family = category['family']\n    genus_family_map[genus] = family\n\n    # Step 2: Create new column with default value of Noneâ„¢\nmain_df['family'] = None\n\n    # Step 3: Update values in new column based on genus -> family mapping\nfor i, row in main_df.iterrows():\n    genus = row['genus']\n    if genus in genus_family_map:\n        family = genus_family_map[genus]\n        main_df.at[i, 'family'] = family\n\nmain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:42:51.380137Z","iopub.execute_input":"2023-04-28T18:42:51.380554Z","iopub.status.idle":"2023-04-28T18:43:42.083079Z","shell.execute_reply.started":"2023-04-28T18:42:51.380513Z","shell.execute_reply":"2023-04-28T18:43:42.080903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filter only the images of plants that are in the Poaceae family\nmain_df = main_df.loc[main_df['family'] == 'Poaceae']\n#Reset index\nmain_df = main_df.reset_index(drop=True)\n\nmain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:42.085872Z","iopub.execute_input":"2023-04-28T18:43:42.086523Z","iopub.status.idle":"2023-04-28T18:43:42.155904Z","shell.execute_reply.started":"2023-04-28T18:43:42.086483Z","shell.execute_reply":"2023-04-28T18:43:42.154985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport timm\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:42.157471Z","iopub.execute_input":"2023-04-28T18:43:42.157852Z","iopub.status.idle":"2023-04-28T18:43:46.736830Z","shell.execute_reply.started":"2023-04-28T18:43:42.157816Z","shell.execute_reply":"2023-04-28T18:43:46.735599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_df['genus'] = pd.factorize(main_df['genus'])[0]\nmain_df","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:46.739139Z","iopub.execute_input":"2023-04-28T18:43:46.739530Z","iopub.status.idle":"2023-04-28T18:43:46.774146Z","shell.execute_reply.started":"2023-04-28T18:43:46.739495Z","shell.execute_reply":"2023-04-28T18:43:46.773141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = main_df.groupby('genus')\n# Split the dataset for each class separately\ntrain_dfs = []\ntest_dfs = []\n\nfor name, group in grouped:\n    # Split the group into train and test sets\n    train, test = train_test_split(group, test_size=0.2, random_state=42)\n    # Add the train and test dataframes to the respective lists\n    train_dfs.append(train)\n    test_dfs.append(test)\n\n# Concatenate the training and evaluation sets for all classes into single DataFrames\ntrain_df_initial = pd.concat(train_dfs)\ntrain_df_initial = train_df_initial.reset_index(drop=True)\n\ntest_df = pd.concat(test_dfs)\ntest_df = test_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:46.775972Z","iopub.execute_input":"2023-04-28T18:43:46.776599Z","iopub.status.idle":"2023-04-28T18:43:47.071058Z","shell.execute_reply.started":"2023-04-28T18:43:46.776559Z","shell.execute_reply":"2023-04-28T18:43:47.069583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped2 = train_df_initial.groupby('genus')\n# Split the dataset for each class separately\ntrain_dfs = []\nval_dfs = []\n\nfor name, group in grouped2:\n    # Split the group into train and test sets\n    train, validation = train_test_split(group, test_size=0.2, random_state=42)\n    # Add the train and test dataframes to the respective lists\n    train_dfs.append(train)\n    val_dfs.append(validation)\n\n# Concatenate the training and evaluation sets for all classes into single DataFrames\ntrain_df = pd.concat(train_dfs)\ntrain_df = train_df.reset_index(drop=True)\n\nval_df = pd.concat(val_dfs)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:47.072567Z","iopub.execute_input":"2023-04-28T18:43:47.072924Z","iopub.status.idle":"2023-04-28T18:43:47.258831Z","shell.execute_reply.started":"2023-04-28T18:43:47.072886Z","shell.execute_reply":"2023-04-28T18:43:47.257820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nepochs = 4\nIM_SIZE = 224\nlearning_rate = 1e-4\n\nX_train, Y_train = train_df[\"image_dir\"].values, train_df[\"genus\"].values\n\nX_val, Y_val = val_df[\"image_dir\"].values, val_df[\"genus\"].values\n\nX_test, Y_test  = test_df[\"image_dir\"].values, test_df[\"genus\"].values\n\nTransform = transforms.Compose([\n     transforms.Resize((IM_SIZE, IM_SIZE)),\n     transforms.ToTensor(),\n     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:47.261061Z","iopub.execute_input":"2023-04-28T18:43:47.261454Z","iopub.status.idle":"2023-04-28T18:43:47.270580Z","shell.execute_reply.started":"2023-04-28T18:43:47.261415Z","shell.execute_reply":"2023-04-28T18:43:47.269314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GetData(Dataset):\n    def __init__(self, FNames, Labels, Transform):\n        self.fnames = FNames\n        self.transform = Transform\n        self.labels = Labels         \n        \n    def __len__(self):\n        return len(self.fnames)\n\n    def __getitem__(self, index):       \n        x = Image.open(self.fnames[index])\n    \n        if \"train\" in self.fnames[index]:             \n            return self.transform(x), self.labels[index]\n        elif \"test\" in self.fnames[index]:            \n            return self.transform(x), self.fnames[index]\n        \n        \nclass GetTestData(Dataset):\n    def __init__(self, FNames, Labels, Transform):\n        self.fnames = FNames\n        self.transform = Transform\n        self.labels = Labels\n        \n    def __len__(self):\n        return len(self.fnames)\n\n    def __getitem__(self, index):       \n        x = Image.open(self.fnames[index])\n        return self.transform(x), self.labels[index]\n\n        \ntrainset = GetData(X_train, Y_train, Transform)\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\nvalset = GetData(X_val, Y_val, Transform)\nvalloader = DataLoader(valset, batch_size=batch_size, shuffle=True)\n\ntestset = GetTestData(X_test, Y_test, Transform)\ntestloader = DataLoader(testset, batch_size=batch_size, shuffle=True)\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nmodel = timm.create_model('resnest269e', pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:47.275897Z","iopub.execute_input":"2023-04-28T18:43:47.276250Z","iopub.status.idle":"2023-04-28T18:43:52.434384Z","shell.execute_reply.started":"2023-04-28T18:43:47.276222Z","shell.execute_reply":"2023-04-28T18:43:52.433232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = train_df['genus'].nunique()\nprint(num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:52.436004Z","iopub.execute_input":"2023-04-28T18:43:52.437044Z","iopub.status.idle":"2023-04-28T18:43:52.445563Z","shell.execute_reply.started":"2023-04-28T18:43:52.436996Z","shell.execute_reply":"2023-04-28T18:43:52.444252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_layers = len(list(model.parameters()))\n\nfor param in model.parameters():\n    param.requires_grad = True\n    \nn_inputs = model.fc.in_features\nlast_layer = nn.Linear(n_inputs, num_classes)\nmodel.fc = last_layer \nif torch.cuda.is_available():\n    model.cuda()\nprint(model.fc.out_features)    \n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n#optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:52.447546Z","iopub.execute_input":"2023-04-28T18:43:52.447909Z","iopub.status.idle":"2023-04-28T18:43:55.416453Z","shell.execute_reply.started":"2023-04-28T18:43:52.447872Z","shell.execute_reply":"2023-04-28T18:43:55.415264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import f1_score\n\ndef train(trainloader, model, criterion, optimizer, scaler, device=torch.device(\"cpu\")):\n    train_acc = 0.0\n    train_loss = 0.0\n    y_true = []\n    y_pred = []\n    for images, labels in tqdm(trainloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast(enabled=True):\n            output = model(images)\n            loss = criterion(output, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            acc = ((output.argmax(dim=1) == labels).float().mean())\n            train_acc += acc\n            train_loss += loss\n            y_true += labels.cpu().numpy().tolist()\n            y_pred += output.argmax(dim=1).cpu().numpy().tolist()\n            \n    train_f1 = f1_score(y_true, y_pred, average=None)\n    train_f1_avg = f1_score(y_true, y_pred, average='macro')\n    return train_acc/len(trainloader), train_loss/len(trainloader), train_f1, train_f1_avg","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:55.417867Z","iopub.execute_input":"2023-04-28T18:43:55.418774Z","iopub.status.idle":"2023-04-28T18:43:55.429909Z","shell.execute_reply.started":"2023-04-28T18:43:55.418731Z","shell.execute_reply":"2023-04-28T18:43:55.428307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(testloader, model, criterion, device=torch.device(\"cpu\")):\n    model.eval()\n    eval_acc = 0.0\n    eval_loss = 0.0\n    y_true = []\n    y_pred = []\n    for images, labels in tqdm(testloader):\n        images = images.to(device)\n        labels = labels.to(device)\n        with torch.no_grad():\n            output = model(images)\n            loss = criterion(output, labels)\n        acc = ((output.argmax(dim=1) == labels).float().mean())\n        eval_acc += acc\n        eval_loss += loss\n        y_true += labels.cpu().numpy().tolist()\n        y_pred += output.argmax(dim=1).cpu().numpy().tolist()\n  \n    eval_f1 = f1_score(y_true, y_pred, average=None)\n    eval_f1_avg = f1_score(y_true, y_pred, average='macro')\n    return eval_acc/len(testloader), eval_loss/len(testloader), eval_f1, eval_f1_avg","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:55.431888Z","iopub.execute_input":"2023-04-28T18:43:55.432341Z","iopub.status.idle":"2023-04-28T18:43:55.444037Z","shell.execute_reply.started":"2023-04-28T18:43:55.432228Z","shell.execute_reply":"2023-04-28T18:43:55.442905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = torch.cuda.amp.GradScaler(enabled=True)\n\ntrain_f1_scores = []  # Initialize an empty list to store training F1 scores\nval_f1_scores = []  # Initialize an empty list to store validation F1 scores\n\n\nfor epoch in range(epochs):\n    train_acc, train_loss, train_f1, train_f1_avg = train(trainloader, model, criterion, optimizer, scaler, device=device)\n    eval_acc, eval_loss, eval_f1, eval_f1_avg = evaluate(valloader, model, criterion, device=torch.device(\"cuda\"))\n\n    train_f1_scores.append(train_f1_avg)  # Store the training F1 score for this epoch\n    val_f1_scores.append(eval_f1_avg)  # Store the validation F1 score for this epoch\n\n    print(f\"Epoch {epoch + 1} | Train Acc: {train_acc*100} | Train Loss: {train_loss} | Train F1 (Avg): {train_f1_avg}\")\n    print(f\"\\t Val Acc: {eval_acc*100} | Val Loss: {eval_loss} | Val F1 (Avg): {eval_f1_avg}\")\n    \n    print(\"F1 score per class (Train):\")\n    for i, f1 in enumerate(train_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"\\nF1 score per class (Validation):\") \n    for i, f1 in enumerate(eval_f1):\n        print(f\"Class {i}: {f1}\")\n\n    print(\"====\"*8)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:43:55.445643Z","iopub.execute_input":"2023-04-28T18:43:55.446208Z","iopub.status.idle":"2023-04-28T18:44:03.281222Z","shell.execute_reply.started":"2023-04-28T18:43:55.446170Z","shell.execute_reply":"2023-04-28T18:44:03.279624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntest_acc = 0.0\ny_true = []\ny_pred = []\n\nmodel = model.to(device)\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Loop through the test set\nwith torch.no_grad():\n    for images, labels in tqdm(testloader, desc=\"Testing\"):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Make predictions\n        output = model(images)\n\n        # Calculate accuracy\n        acc = (output.argmax(dim=1) == labels).float().mean()\n        test_acc += acc\n\n        # Store true labels and predicted labels for other metrics\n        y_true += labels.cpu().numpy().tolist()\n        y_pred += output.argmax(dim=1).cpu().numpy().tolist()\n\n# Calculate the final test accuracy\ntest_acc = test_acc / len(testloader)\nprint(f\"Test accuracy: {test_acc:.2%}\")\n\n# Calculate the classification report, which includes the F1 score for all classes\nreport = classification_report(y_true, y_pred, output_dict=True)\n\n# Print the classification report\nfor class_label, metrics in report.items():\n    if class_label.isdigit():\n        print(f\"Class {class_label}: F1 score = {metrics['f1-score']:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:44:03.282511Z","iopub.status.idle":"2023-04-28T18:44:03.283553Z","shell.execute_reply.started":"2023-04-28T18:44:03.283270Z","shell.execute_reply":"2023-04-28T18:44:03.283298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(train_f1_scores, label=\"Train F1 (Avg)\")\nplt.plot(val_f1_scores, label=\"Validation F1 (Avg)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"F1 Score\")\nplt.title(f\"F1 Scores Over Epochs\")\nplt.legend()\nplt.xticks(range(len(train_f1_scores)), range(1, len(train_f1_scores) + 1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T18:44:03.285101Z","iopub.status.idle":"2023-04-28T18:44:03.285986Z","shell.execute_reply.started":"2023-04-28T18:44:03.285706Z","shell.execute_reply":"2023-04-28T18:44:03.285731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}